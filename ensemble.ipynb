{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "from typing import *\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "from time import time\n",
    "from functools import lru_cache\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import logging\n",
    "import scipy\n",
    "from scipy.special import softmax\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "root = Path(\"/data/natsuki/dataset_atmaCup11\")\n",
    "\n",
    "names = [\"atma11simple_j4e5nofreeze\", \"atma11sortingdate_j4e5nofreeze\", \"atma11onehot_j4e5nofreeze\", \"atma11materialstechniques_j4e5nofreeze\"]\n",
    "epoch = 10\n",
    "\n",
    "# https://github.com/microsoft/LightGBM/blob/master/examples/python-guide/simple_example.py\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9, #学習の高速化と過学習の抑制に使用される．データの特徴量のfeature_fraction * 100 % だけ使用する．\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'force_col_wise': True,\n",
    "    \"verbose\": -1, # suppress warning\n",
    "}\n",
    "\n",
    "def aug(\n",
    "    arr: List[np.ndarray],\n",
    "    funcs=\"mean\",\n",
    "    object_id=None,\n",
    "    ) -> np.ndarray:\n",
    "    seq = list()\n",
    "    if funcs[:4] == \"all,\":\n",
    "        seq += [np.array(arr).flatten()]\n",
    "        funcs = funcs[4:]\n",
    "    seq += [ getattr(np, func)(arr, axis=0).flatten() for func in funcs.split(\",\") ]\n",
    "    return np.concatenate(seq)\n",
    "def enc(t: int):\n",
    "    return t\n",
    "@lru_cache(maxsize=None)\n",
    "def load_df(path: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(path).set_index(\"object_id\", drop=False)\n",
    "@lru_cache(maxsize=None)\n",
    "def load_dict(path: Path) -> Dict[str, List[np.ndarray]]:\n",
    "    with open(path, \"rb\") as f:\n",
    "        _dict = pickle.load(f)\n",
    "        return _dict\n",
    "def post_process(\n",
    "    pred: np.ndarray,\n",
    "    suffix=None,\n",
    "    test_df=None,\n",
    "    thr=None,\n",
    "    ratio=None,\n",
    "    width=None,\n",
    "    ) -> np.ndarray:\n",
    "    simple_dict = load_dict(root/\"checkpoints\"/f\"atma11simple_j4e5nofreeze_{suffix}\"/f\"epoch10_{suffix}_test_features2.pkl\")\n",
    "    simple_np = np.array([ np.mean(simple_dict[object_id], axis=0) for object_id in test_df[\"object_id\"] ]).flatten()\n",
    "    pred = ratio*pred + (1-ratio)*simple_np\n",
    "\n",
    "    onehot_dict = load_dict(root/\"checkpoints\"/f\"atma11onehot_j4e5nofreeze_{suffix}\"/f\"epoch10_{suffix}_test_features2.pkl\")\n",
    "    onehot_np = np.array([ np.mean(onehot_dict[object_id], axis=0).reshape(4) for object_id in test_df[\"object_id\"] ])\n",
    "    for i in range(4):\n",
    "        for j in np.where(onehot_np[:, i] > thr)[0]:\n",
    "            pred[j] = i\n",
    "    for i in range(len(pred)):\n",
    "        for j in range(4):\n",
    "            if j-width < pred[i] < j+width:\n",
    "                pred[i] = j\n",
    "                break\n",
    "    return pred.clip(0, 3)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "process = \"clip\"\n",
    "funcs = \"mean,max,min,var\"\n",
    "coef = 1\n",
    "thr = 0.94\n",
    "ratio = 0.5\n",
    "width = 0 # 0.5を超えるのはナンセンス 意味なかった…\n",
    "\n",
    "scores = list()\n",
    "stops = list()\n",
    "for suffix in [\"3fold0\", \"3fold1\", \"3fold2\", \"all\"]:\n",
    "    train_df = load_df(root/f\"{suffix}_train.csv\")\n",
    "    test_df = load_df(root/f\"{suffix}_test.csv\")\n",
    "    train_target = np.array([enc(train_df.loc[object_id][\"target\"]) for object_id in train_df[\"object_id\"]]).reshape(-1, 1)\n",
    "    if suffix != \"all\":\n",
    "        test_target = np.array([enc(test_df.loc[object_id][\"target\"]) for object_id in test_df[\"object_id\"]]).reshape(-1, 1)\n",
    "    test_features = list()\n",
    "    train_features = list()\n",
    "    for name in names:\n",
    "        train_dict = load_dict(root/\"checkpoints\"/f\"{name}_{suffix}\"/f\"epoch{epoch}_{suffix}_train_features2.pkl\")\n",
    "        test_dict = load_dict(root/\"checkpoints\"/f\"{name}_{suffix}\"/f\"epoch{epoch}_{suffix}_test_features2.pkl\")\n",
    "        train_features.append( np.array([aug(train_dict[object_id], funcs, object_id) for object_id in train_df[\"object_id\"]]) )\n",
    "        test_features.append( np.array([aug(test_dict[object_id], funcs, object_id) for object_id in test_df[\"object_id\"]]))\n",
    "    train_features = np.concatenate(train_features, axis=1)\n",
    "    test_features = np.concatenate(test_features, axis=1)\n",
    "    train_dataset = lgb.Dataset(train_features, label=train_target)\n",
    "    if suffix != \"all\":\n",
    "        print(f\" Start CV {suffix} \".center(50, \"#\"))\n",
    "        test_dataset = lgb.Dataset(test_features, label=test_target)\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=(train_dataset, test_dataset),\n",
    "            num_boost_round=10000,\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=1\n",
    "        )\n",
    "        pred = model.predict(test_features)\n",
    "        pred = post_process(pred, suffix=suffix, test_df=test_df, thr=thr, ratio=ratio, width=width) # XXX\n",
    "        scores.append( mse(test_target, pred)**.5 )\n",
    "        stops.append( model.best_iteration )\n",
    "        print(f\" Finished CV {suffix} {model.best_iteration=} \".center(50, \"#\"))\n",
    "    if suffix == \"all\":\n",
    "        print(f\" Start Pred {suffix} \".center(50, \"#\"))\n",
    "        score = np.mean(scores)\n",
    "        stop = int(np.mean(stops)*coef)\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set=train_dataset,\n",
    "            valid_sets=(train_dataset,),\n",
    "            num_boost_round=stop,\n",
    "            early_stopping_rounds=None,\n",
    "            verbose_eval=1\n",
    "        )\n",
    "        pred = model.predict(test_features)\n",
    "        pred = post_process(pred, suffix=suffix, test_df=test_df, thr=thr, ratio=ratio, width=width) #XXX\n",
    "        pred_df = pd.DataFrame(pred, columns=[\"target\"])\n",
    "        fn = f\"{str(int(time()))[-5:]}_{str(score)[:6]}\".replace(\".\", \"\")+\".csv\"\n",
    "        pred_df.to_csv(f\"./submissions/{fn}\", index=False)\n",
    "        clear_output()\n",
    "        print(f\" Finished {fn} \".center(50, \"#\"))\n",
    "old_score = score"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "######## Finished 0.7174 31007_07174.csv #########\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('atmaCup11': conda)"
  },
  "interpreter": {
   "hash": "a36cd820be0eaca38c52ebedd48039812cfccf3c99d2a07a6b762e4f499bf7df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}